{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.model_selection as MS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"TRAIN.csv\",index_col=0)\n",
    "test = pd.read_csv(\"TEST.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\"readmitted\", axis=1)\n",
    "y = train[\"readmitted\"]\n",
    "X_test = test.drop(\"readmitted\", axis=1)\n",
    "y_test = test[\"readmitted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?Add others? Bagging or sth, work on previous work of M-B group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other than RF, ET and DT bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.01      0.02      7755\n",
      "           1       0.89      1.00      0.94     60750\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     68505\n",
      "   macro avg       0.71      0.51      0.48     68505\n",
      "weighted avg       0.85      0.89      0.84     68505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without tampering probabilities nor any unbalanced method:\n",
    "cv = MS.KFold(n_splits=10)\n",
    "clf = RandomForestClassifier(n_estimators = 100) # NOTE: we've tried tampering with the parameters, but it is mostly the same (changing to entropy or pruning rules)\n",
    "y_pred = MS.cross_val_predict(clf, X, y, cv = cv)\n",
    "print(classification_report(y, y_pred))\n",
    "# Dismally low results, to be expected given the lack of examples of class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampering with probablities:\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "y_probs = MS.cross_val_predict(clf, X, y, cv = cv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.66      0.24      7755\n",
      "           1       0.92      0.52      0.67     60750\n",
      "\n",
      "   micro avg       0.54      0.54      0.54     68505\n",
      "   macro avg       0.54      0.59      0.46     68505\n",
      "weighted avg       0.84      0.54      0.62     68505\n",
      "\n",
      "Threshold: 0.12000000000000001\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.56      0.25      7755\n",
      "           1       0.92      0.62      0.74     60750\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     68505\n",
      "   macro avg       0.54      0.59      0.50     68505\n",
      "weighted avg       0.83      0.62      0.69     68505\n",
      "\n",
      "Threshold: 0.14\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.48      0.25      7755\n",
      "           1       0.91      0.71      0.80     60750\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     68505\n",
      "   macro avg       0.54      0.59      0.53     68505\n",
      "weighted avg       0.83      0.68      0.74     68505\n",
      "\n",
      "Threshold: 0.16000000000000003\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.39      0.25      7755\n",
      "           1       0.91      0.78      0.84     60750\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     68505\n",
      "   macro avg       0.55      0.58      0.54     68505\n",
      "weighted avg       0.83      0.73      0.77     68505\n",
      "\n",
      "Threshold: 0.18000000000000002\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.32      0.24      7755\n",
      "           1       0.91      0.83      0.87     60750\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     68505\n",
      "   macro avg       0.55      0.58      0.56     68505\n",
      "weighted avg       0.83      0.77      0.80     68505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0.1, 0.2, 0.02):\n",
    "    y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "    print(\"Threshold: \"+ str(thr) + \"\\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old dataset shape Counter({1: 60750, 0: 7755})\n",
      "New dataset shape Counter({1: 60750, 0: 60750})\n"
     ]
    }
   ],
   "source": [
    "# Tampering with dataset distribution (SMOTE)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=20)\n",
    "X_n, y_n = sm.fit_sample(X, y)\n",
    "print('Old dataset shape {}'.format(Counter(y)))\n",
    "print('New dataset shape {}'.format(Counter(y_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94     60750\n",
      "           1       0.90      0.99      0.95     60750\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    121500\n",
      "   macro avg       0.95      0.94      0.94    121500\n",
      "weighted avg       0.95      0.94      0.94    121500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As a note, we've seen studies do something like this, but it is cheating:\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "y_pred = MS.cross_val_predict(clf, X_n, y_n, cv = cv)\n",
    "print(classification_report(y_n, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What should be done instead:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X2, X2_test, y2, y2_test = train_test_split(X, y, random_state=42,test_size=0.3)\n",
    "sm = SMOTE(random_state=20)\n",
    "X_n, y_n = sm.fit_sample(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.03      0.05      2279\n",
      "           1       0.89      0.99      0.94     18273\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     20552\n",
      "   macro avg       0.62      0.51      0.49     20552\n",
      "weighted avg       0.83      0.89      0.84     20552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(X_n, y_n)\n",
    "y_pred=clf.predict(X2_test)\n",
    "print(classification_report(y2_test, y_pred))\n",
    "# Not better than first try, this is the real outcome and not the one with CV_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using both techniques simultaneously\n",
    "y_probs = clf.predict_proba(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.75      0.23      2279\n",
      "           1       0.93      0.40      0.56     18273\n",
      "\n",
      "   micro avg       0.44      0.44      0.44     20552\n",
      "   macro avg       0.53      0.57      0.39     20552\n",
      "weighted avg       0.84      0.44      0.52     20552\n",
      "\n",
      "Threshold: 0.12000000000000001\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.67      0.23      2279\n",
      "           1       0.92      0.49      0.64     18273\n",
      "\n",
      "   micro avg       0.51      0.51      0.51     20552\n",
      "   macro avg       0.53      0.58      0.44     20552\n",
      "weighted avg       0.84      0.51      0.60     20552\n",
      "\n",
      "Threshold: 0.14\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.60      0.24      2279\n",
      "           1       0.92      0.57      0.70     18273\n",
      "\n",
      "   micro avg       0.57      0.57      0.57     20552\n",
      "   macro avg       0.53      0.58      0.47     20552\n",
      "weighted avg       0.83      0.57      0.65     20552\n",
      "\n",
      "Threshold: 0.16000000000000003\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.52      0.24      2279\n",
      "           1       0.92      0.65      0.76     18273\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     20552\n",
      "   macro avg       0.54      0.58      0.50     20552\n",
      "weighted avg       0.83      0.63      0.70     20552\n",
      "\n",
      "Threshold: 0.18000000000000002\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.45      0.24      2279\n",
      "           1       0.91      0.71      0.80     18273\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     20552\n",
      "   macro avg       0.54      0.58      0.52     20552\n",
      "weighted avg       0.83      0.68      0.74     20552\n",
      "\n",
      "Threshold: 0.2\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.39      0.24      2279\n",
      "           1       0.91      0.76      0.83     18273\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     20552\n",
      "   macro avg       0.54      0.58      0.54     20552\n",
      "weighted avg       0.83      0.72      0.77     20552\n",
      "\n",
      "Threshold: 0.22000000000000003\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.34      0.24      2279\n",
      "           1       0.91      0.81      0.86     18273\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     20552\n",
      "   macro avg       0.54      0.57      0.55     20552\n",
      "weighted avg       0.83      0.76      0.79     20552\n",
      "\n",
      "Threshold: 0.24000000000000002\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.29      0.23      2279\n",
      "           1       0.91      0.85      0.88     18273\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     20552\n",
      "   macro avg       0.55      0.57      0.55     20552\n",
      "weighted avg       0.83      0.79      0.80     20552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0.1, 0.25, 0.02):\n",
    "    y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "    print(\"Threshold: \"+ str(thr) + \"\\n\", classification_report(y2_test, y_pred))\n",
    "# Best results are without Upsampling and probablities at 0.12 threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest final report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.57      0.26      3409\n",
      "           1       0.92      0.63      0.75     25951\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     29360\n",
      "   macro avg       0.54      0.60      0.50     29360\n",
      "weighted avg       0.83      0.62      0.69     29360\n",
      "\n",
      "Random forest final report\n",
      " [[ 1927  1482]\n",
      " [ 9661 16290]]\n"
     ]
    }
   ],
   "source": [
    "# Final Test Random forest score (No upsampling, thr = .12)\n",
    "# Decision why: Best f1 score with recall above .5.\n",
    "# Note, threshold 'happens to be equal' to #class0 in training /#class1 in training. (Explain in Doc) \n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(X, y)\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "thr = 0.12\n",
    "y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "print(\"Random forest final report\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Random forest final CM\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5f838f880400>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MS' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "cv = MS.KFold(n_splits=10)\n",
    "clf = ExtraTreesClassifier(n_estimators = 100)\n",
    "y_probs = MS.cross_val_predict(clf, X, y, cv = cv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.60      0.24      7755\n",
      "           1       0.92      0.57      0.70     60750\n",
      "\n",
      "   micro avg       0.57      0.57      0.57     68505\n",
      "   macro avg       0.53      0.58      0.47     68505\n",
      "weighted avg       0.83      0.57      0.65     68505\n",
      "\n",
      "Threshold: 0.12000000000000001\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.51      0.24      7755\n",
      "           1       0.91      0.65      0.76     60750\n",
      "\n",
      "   micro avg       0.63      0.63      0.63     68505\n",
      "   macro avg       0.54      0.58      0.50     68505\n",
      "weighted avg       0.83      0.63      0.70     68505\n",
      "\n",
      "Threshold: 0.14\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.44      0.24      7755\n",
      "           1       0.91      0.72      0.80     60750\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     68505\n",
      "   macro avg       0.54      0.58      0.52     68505\n",
      "weighted avg       0.83      0.69      0.74     68505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0.10, 0.16, 0.02):\n",
    "    y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "    print(\"Threshold: \"+ str(thr) + \"\\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaggingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2749f8ef9437>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Final ET with threshold .12 (most reasonable in recall-precision)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mthr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.12\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BaggingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Final ET with threshold .12 (most reasonable in recall-precision)\n",
    "clf = ExtraTreesClassifier(n_estimators = 100)\n",
    "clf.fit(X, y)\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "thr = 0.12\n",
    "y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "print(\"Extra Trees final report\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Extra Trees final CM\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other baggings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree bagging:\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cv = MS.KFold(n_splits=10)\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100)\n",
    "y_probs = MS.cross_val_predict(clf, X, y, cv = cv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.12\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.60      0.24      7755\n",
      "           1       0.92      0.56      0.70     60750\n",
      "\n",
      "   micro avg       0.57      0.57      0.57     68505\n",
      "   macro avg       0.53      0.58      0.47     68505\n",
      "weighted avg       0.83      0.57      0.65     68505\n",
      "\n",
      "Threshold: 0.13999999999999999\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.56      0.24      7755\n",
      "           1       0.92      0.60      0.73     60750\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     68505\n",
      "   macro avg       0.53      0.58      0.48     68505\n",
      "weighted avg       0.83      0.60      0.67     68505\n",
      "\n",
      "Threshold: 0.15999999999999998\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.49      0.24      7755\n",
      "           1       0.91      0.67      0.77     60750\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     68505\n",
      "   macro avg       0.54      0.58      0.51     68505\n",
      "weighted avg       0.83      0.65      0.71     68505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0.12, 0.18, 0.02):\n",
    "    y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "    print(\"Threshold: \"+ str(thr) + \"\\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Bagging final report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.53      0.25      3409\n",
      "           1       0.91      0.64      0.75     25951\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     29360\n",
      "   macro avg       0.54      0.58      0.50     29360\n",
      "weighted avg       0.82      0.62      0.69     29360\n",
      "\n",
      "Tree Bagging final CM\n",
      " [[ 1802  1607]\n",
      " [ 9451 16500]]\n"
     ]
    }
   ],
   "source": [
    "# Final bagging with threshold .14 (most reasonable in recall-precision)\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100)\n",
    "clf.fit(X, y)\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "thr = 0.14\n",
    "y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "print(\"Tree Bagging final report\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Tree Bagging final CM\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost using decision stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as MS\n",
    "cv = MS.KFold(n_splits=10)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100) #default uses decision stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.01      0.03      7755\n",
      "          1       0.89      1.00      0.94     60750\n",
      "\n",
      "avg / total       0.84      0.89      0.84     68505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = MS.cross_val_predict(clf, X, y, cv = cv)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampering with probablities:\n",
    "y_probs = MS.cross_val_predict(clf, X, y, cv = cv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.12      0.96      0.21      7755\n",
      "          1       0.95      0.10      0.19     60750\n",
      "\n",
      "avg / total       0.86      0.20      0.19     68505\n",
      "\n",
      "Threshold: 0.494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.15      0.77      0.25      7755\n",
      "          1       0.94      0.43      0.59     60750\n",
      "\n",
      "avg / total       0.85      0.46      0.55     68505\n",
      "\n",
      "Threshold: 0.495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.18      0.52      0.27      7755\n",
      "          1       0.92      0.70      0.80     60750\n",
      "\n",
      "avg / total       0.84      0.68      0.74     68505\n",
      "\n",
      "Threshold: 0.496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.22      0.28      0.25      7755\n",
      "          1       0.90      0.87      0.89     60750\n",
      "\n",
      "avg / total       0.83      0.81      0.82     68505\n",
      "\n",
      "Threshold: 0.497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.27      0.14      0.18      7755\n",
      "          1       0.90      0.95      0.92     60750\n",
      "\n",
      "avg / total       0.83      0.86      0.84     68505\n",
      "\n",
      "Threshold: 0.498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.34      0.06      0.11      7755\n",
      "          1       0.89      0.98      0.94     60750\n",
      "\n",
      "avg / total       0.83      0.88      0.84     68505\n",
      "\n",
      "Threshold: 0.499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.03      0.05      7755\n",
      "          1       0.89      1.00      0.94     60750\n",
      "\n",
      "avg / total       0.84      0.89      0.84     68505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0.493, 0.499, 0.001):\n",
    "    y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "    print(\"Threshold: \"+ str(thr) + \"\\n\", classification_report(y, y_pred))\n",
    "# best threshold is 0.495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old dataset shape Counter({1: 60750, 0: 7755})\n",
      "New dataset shape Counter({1: 60750, 0: 60750})\n"
     ]
    }
   ],
   "source": [
    "# Tampering with dataset distribution (SMOTE)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=20)\n",
    "X_n, y_n = sm.fit_sample(X, y)\n",
    "print('Old dataset shape {}'.format(Counter(y)))\n",
    "print('New dataset shape {}'.format(Counter(y_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X2, X2_test, y2, y2_test = train_test_split(X, y, random_state=42,test_size=0.3)\n",
    "sm = SMOTE(random_state=20)\n",
    "X_n, y_n = sm.fit_sample(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.23      0.10      0.13      2279\n",
      "          1       0.89      0.96      0.93     18273\n",
      "\n",
      "avg / total       0.82      0.86      0.84     20552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100) #default uses decision stump\n",
    "clf.fit(X_n, y_n)\n",
    "y_pred=clf.predict(X2_test)\n",
    "print(classification_report(y2_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using both techniques simultaneously\n",
    "y_probs = clf.predict_proba(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.11      1.00      0.20      2279\n",
      "          1       0.96      0.01      0.01     18273\n",
      "\n",
      "avg / total       0.86      0.12      0.03     20552\n",
      "\n",
      "Threshold: 0.494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.11      0.99      0.20      2279\n",
      "          1       0.96      0.04      0.08     18273\n",
      "\n",
      "avg / total       0.86      0.15      0.09     20552\n",
      "\n",
      "Threshold: 0.495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.12      0.93      0.21      2279\n",
      "          1       0.94      0.13      0.24     18273\n",
      "\n",
      "avg / total       0.85      0.22      0.23     20552\n",
      "\n",
      "Threshold: 0.496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.13      0.79      0.22      2279\n",
      "          1       0.93      0.34      0.50     18273\n",
      "\n",
      "avg / total       0.84      0.39      0.47     20552\n",
      "\n",
      "Threshold: 0.497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.16      0.56      0.24      2279\n",
      "          1       0.92      0.62      0.74     18273\n",
      "\n",
      "avg / total       0.83      0.62      0.69     20552\n",
      "\n",
      "Threshold: 0.498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.35      0.25      2279\n",
      "          1       0.91      0.82      0.86     18273\n",
      "\n",
      "avg / total       0.83      0.77      0.79     20552\n",
      "\n",
      "Threshold: 0.499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.20      0.20      2279\n",
      "          1       0.90      0.90      0.90     18273\n",
      "\n",
      "avg / total       0.82      0.83      0.82     20552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0.493, 0.499, 0.001):\n",
    "    y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "    print(\"Threshold: \"+ str(thr) + \"\\n\", classification_report(y2_test, y_pred))\n",
    "# Best threshold at 0.497\n",
    "# Best results with and without upsampling present no significant difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost with decision stumps final report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.18      0.51      0.27      3409\n",
      "          1       0.92      0.70      0.80     25951\n",
      "\n",
      "avg / total       0.83      0.68      0.74     29360\n",
      "\n",
      "Adaboost with decision stumps final CM\n",
      " [[ 1724  1685]\n",
      " [ 7657 18294]]\n"
     ]
    }
   ],
   "source": [
    "# Final Test Adaboost with decision stumps score:\n",
    "clf = AdaBoostClassifier(n_estimators=100) #default uses decision stump\n",
    "clf.fit(X, y)\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "thr = 0.495\n",
    "y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "print(\"Adaboost with decision stumps final report\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Adaboost with decision stumps final CM\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost using decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as MS\n",
    "cv = MS.KFold(n_splits=10)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.23      0.06      0.09      7755\n",
      "          1       0.89      0.98      0.93     60750\n",
      "\n",
      "avg / total       0.82      0.87      0.84     68505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = MS.cross_val_predict(clf, X, y, cv = cv)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampering with probablities:\n",
    "y_probs = MS.cross_val_predict(clf, X, y, cv = cv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.12      0.79      0.21      7755\n",
      "          1       0.91      0.26      0.41     60750\n",
      "\n",
      "avg / total       0.82      0.32      0.39     68505\n",
      "\n",
      "Threshold: 0.491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.12      0.76      0.21      7755\n",
      "          1       0.91      0.31      0.47     60750\n",
      "\n",
      "avg / total       0.82      0.36      0.44     68505\n",
      "\n",
      "Threshold: 0.492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.13      0.71      0.22      7755\n",
      "          1       0.91      0.38      0.54     60750\n",
      "\n",
      "avg / total       0.82      0.42      0.50     68505\n",
      "\n",
      "Threshold: 0.493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.64      0.22      7755\n",
      "          1       0.91      0.48      0.63     60750\n",
      "\n",
      "avg / total       0.82      0.49      0.58     68505\n",
      "\n",
      "Threshold: 0.494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.54      0.23      7755\n",
      "          1       0.91      0.60      0.72     60750\n",
      "\n",
      "avg / total       0.82      0.59      0.66     68505\n",
      "\n",
      "Threshold: 0.495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.16      0.41      0.23      7755\n",
      "          1       0.91      0.72      0.80     60750\n",
      "\n",
      "avg / total       0.82      0.69      0.74     68505\n",
      "\n",
      "Threshold: 0.496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.29      0.22      7755\n",
      "          1       0.90      0.83      0.86     60750\n",
      "\n",
      "avg / total       0.82      0.76      0.79     68505\n",
      "\n",
      "Threshold: 0.497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.19      0.19      7755\n",
      "          1       0.90      0.90      0.90     60750\n",
      "\n",
      "avg / total       0.82      0.82      0.82     68505\n",
      "\n",
      "Threshold: 0.498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.21      0.12      0.15      7755\n",
      "          1       0.89      0.94      0.92     60750\n",
      "\n",
      "avg / total       0.82      0.85      0.83     68505\n",
      "\n",
      "Threshold: 0.499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.22      0.08      0.12      7755\n",
      "          1       0.89      0.96      0.93     60750\n",
      "\n",
      "avg / total       0.82      0.86      0.83     68505\n",
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.23      0.06      0.09      7755\n",
      "          1       0.89      0.98      0.93     60750\n",
      "\n",
      "avg / total       0.82      0.87      0.84     68505\n",
      "\n",
      "Threshold: 0.501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.24      0.04      0.07      7755\n",
      "          1       0.89      0.98      0.93     60750\n",
      "\n",
      "avg / total       0.82      0.88      0.84     68505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0.49, 0.501, 0.001):\n",
    "    y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "    print(\"Threshold: \"+ str(thr) + \"\\n\", classification_report(y, y_pred))\n",
    "# best threshold is 0.494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old dataset shape Counter({1: 60750, 0: 7755})\n",
      "New dataset shape Counter({1: 60750, 0: 60750})\n"
     ]
    }
   ],
   "source": [
    "# Tampering with dataset distribution (SMOTE)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=20)\n",
    "X_n, y_n = sm.fit_sample(X, y)\n",
    "print('Old dataset shape {}'.format(Counter(y)))\n",
    "print('New dataset shape {}'.format(Counter(y_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X2, X2_test, y2, y2_test = train_test_split(X, y, random_state=42,test_size=0.3)\n",
    "sm = SMOTE(random_state=20)\n",
    "X_n, y_n = sm.fit_sample(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.22      0.07      0.10      2279\n",
      "          1       0.89      0.97      0.93     18273\n",
      "\n",
      "avg / total       0.82      0.87      0.84     20552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),n_estimators=100)\n",
    "clf.fit(X_n, y_n)\n",
    "y_pred=clf.predict(X2_test)\n",
    "print(classification_report(y2_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using both techniques simultaneously\n",
    "y_probs = clf.predict_proba(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.12      0.77      0.21      2279\n",
      "          1       0.91      0.30      0.45     18273\n",
      "\n",
      "avg / total       0.82      0.35      0.43     20552\n",
      "\n",
      "Threshold: 0.491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.12      0.73      0.21      2279\n",
      "          1       0.91      0.36      0.51     18273\n",
      "\n",
      "avg / total       0.83      0.40      0.48     20552\n",
      "\n",
      "Threshold: 0.492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.13      0.68      0.22      2279\n",
      "          1       0.92      0.43      0.58     18273\n",
      "\n",
      "avg / total       0.83      0.45      0.54     20552\n",
      "\n",
      "Threshold: 0.493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.13      0.60      0.22      2279\n",
      "          1       0.91      0.51      0.65     18273\n",
      "\n",
      "avg / total       0.82      0.52      0.61     20552\n",
      "\n",
      "Threshold: 0.494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.51      0.22      2279\n",
      "          1       0.91      0.61      0.73     18273\n",
      "\n",
      "avg / total       0.82      0.60      0.67     20552\n",
      "\n",
      "Threshold: 0.495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.15      0.41      0.22      2279\n",
      "          1       0.91      0.72      0.80     18273\n",
      "\n",
      "avg / total       0.82      0.68      0.74     20552\n",
      "\n",
      "Threshold: 0.496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.31      0.22      2279\n",
      "          1       0.90      0.81      0.85     18273\n",
      "\n",
      "avg / total       0.82      0.75      0.78     20552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0.490, 0.496, 0.001):\n",
    "    y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "    print(\"Threshold: \"+ str(thr) + \"\\n\", classification_report(y2_test, y_pred))\n",
    "# Best threshold at 0.493\n",
    "# Best results with and without upsampling present no significant difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost with decision trees final report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.15      0.55      0.23      3409\n",
      "          1       0.91      0.59      0.71     25951\n",
      "\n",
      "avg / total       0.82      0.58      0.66     29360\n",
      "\n",
      "Adaboost with decision trees final CM\n",
      " [[ 1862  1547]\n",
      " [10768 15183]]\n"
     ]
    }
   ],
   "source": [
    "# Final Test Adaboost with decision trees score:\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),n_estimators=100)\n",
    "clf.fit(X, y)\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "thr = 0.494\n",
    "y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "print(\"Adaboost with decision trees final report\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Adaboost with decision trees final CM\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.01      0.03      7755\n",
      "          1       0.89      1.00      0.94     60750\n",
      "\n",
      "avg / total       0.85      0.89      0.84     68505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = MS.cross_val_predict(clf, X, y, cv = cv)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampering with probablities:\n",
    "y_probs = MS.cross_val_predict(clf, X, y, cv = cv, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.80      0.24      7755\n",
      "          1       0.94      0.40      0.56     60750\n",
      "\n",
      "avg / total       0.85      0.44      0.52     68505\n",
      "\n",
      "Threshold: 0.09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.16      0.72      0.26      7755\n",
      "          1       0.93      0.50      0.65     60750\n",
      "\n",
      "avg / total       0.85      0.52      0.61     68505\n",
      "\n",
      "Threshold: 0.09999999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.16      0.66      0.26      7755\n",
      "          1       0.93      0.57      0.71     60750\n",
      "\n",
      "avg / total       0.84      0.58      0.66     68505\n",
      "\n",
      "Threshold: 0.10999999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.62      0.27      7755\n",
      "          1       0.93      0.62      0.74     60750\n",
      "\n",
      "avg / total       0.84      0.62      0.69     68505\n",
      "\n",
      "Threshold: 0.11999999999999998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.18      0.57      0.27      7755\n",
      "          1       0.92      0.67      0.78     60750\n",
      "\n",
      "avg / total       0.84      0.66      0.72     68505\n",
      "\n",
      "Threshold: 0.12999999999999998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.51      0.27      7755\n",
      "          1       0.92      0.72      0.81     60750\n",
      "\n",
      "avg / total       0.84      0.70      0.75     68505\n",
      "\n",
      "Threshold: 0.13999999999999996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.45      0.27      7755\n",
      "          1       0.92      0.76      0.83     60750\n",
      "\n",
      "avg / total       0.83      0.73      0.77     68505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0.08, 0.15, 0.01):\n",
    "    y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "    print(\"Threshold: \"+ str(thr) + \"\\n\", classification_report(y, y_pred))\n",
    "# best threshold is 0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old dataset shape Counter({1: 60750, 0: 7755})\n",
      "New dataset shape Counter({1: 60750, 0: 60750})\n"
     ]
    }
   ],
   "source": [
    "# Tampering with dataset distribution (SMOTE)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=20)\n",
    "X_n, y_n = sm.fit_sample(X, y)\n",
    "print('Old dataset shape {}'.format(Counter(y)))\n",
    "print('New dataset shape {}'.format(Counter(y_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X2, X2_test, y2, y2_test = train_test_split(X, y, random_state=42,test_size=0.3)\n",
    "sm = SMOTE(random_state=20)\n",
    "X_n, y_n = sm.fit_sample(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.34      0.04      0.07      2279\n",
      "          1       0.89      0.99      0.94     18273\n",
      "\n",
      "avg / total       0.83      0.88      0.84     20552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100)\n",
    "clf.fit(X_n, y_n)\n",
    "y_pred=clf.predict(X2_test)\n",
    "print(classification_report(y2_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using both techniques simultaneously\n",
    "y_probs = clf.predict_proba(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.73      0.23      2279\n",
      "          1       0.93      0.43      0.59     18273\n",
      "\n",
      "avg / total       0.84      0.47      0.55     20552\n",
      "\n",
      "Threshold: 0.21000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.69      0.24      2279\n",
      "          1       0.93      0.48      0.64     18273\n",
      "\n",
      "avg / total       0.84      0.51      0.59     20552\n",
      "\n",
      "Threshold: 0.22000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.15      0.65      0.24      2279\n",
      "          1       0.92      0.53      0.67     18273\n",
      "\n",
      "avg / total       0.84      0.54      0.62     20552\n",
      "\n",
      "Threshold: 0.23000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.15      0.62      0.25      2279\n",
      "          1       0.92      0.57      0.71     18273\n",
      "\n",
      "avg / total       0.84      0.58      0.66     20552\n",
      "\n",
      "Threshold: 0.24000000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.16      0.58      0.25      2279\n",
      "          1       0.92      0.62      0.74     18273\n",
      "\n",
      "avg / total       0.84      0.61      0.68     20552\n",
      "\n",
      "Threshold: 0.25000000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.16      0.54      0.25      2279\n",
      "          1       0.92      0.65      0.76     18273\n",
      "\n",
      "avg / total       0.84      0.64      0.71     20552\n",
      "\n",
      "Threshold: 0.26000000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.50      0.25      2279\n",
      "          1       0.92      0.69      0.79     18273\n",
      "\n",
      "avg / total       0.83      0.67      0.73     20552\n",
      "\n",
      "Threshold: 0.2700000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.46      0.25      2279\n",
      "          1       0.92      0.72      0.81     18273\n",
      "\n",
      "avg / total       0.83      0.69      0.75     20552\n",
      "\n",
      "Threshold: 0.2800000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.18      0.43      0.25      2279\n",
      "          1       0.91      0.75      0.83     18273\n",
      "\n",
      "avg / total       0.83      0.72      0.76     20552\n",
      "\n",
      "Threshold: 0.2900000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.18      0.39      0.25      2279\n",
      "          1       0.91      0.78      0.84     18273\n",
      "\n",
      "avg / total       0.83      0.74      0.78     20552\n",
      "\n",
      "Threshold: 0.3000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.19      0.36      0.25      2279\n",
      "          1       0.91      0.81      0.86     18273\n",
      "\n",
      "avg / total       0.83      0.76      0.79     20552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0.2, 0.31, 0.01):\n",
    "    y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "    print(\"Threshold: \"+ str(thr) + \"\\n\", classification_report(y2_test, y_pred))\n",
    "# Best threshold at 0.23\n",
    "# Best results without sampling and with threshold 0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting final report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.18      0.61      0.27      3409\n",
      "          1       0.92      0.63      0.75     25951\n",
      "\n",
      "avg / total       0.84      0.62      0.69     29360\n",
      "\n",
      "Gradient boosting final CM\n",
      " [[ 2075  1334]\n",
      " [ 9702 16249]]\n"
     ]
    }
   ],
   "source": [
    "# Final Test Adaboost with decision trees score:\n",
    "clf = GradientBoostingClassifier(n_estimators=100)\n",
    "clf.fit(X, y)\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "thr = 0.11\n",
    "y_pred = [0 if p>thr else 1 for p in y_probs[:,0]]\n",
    "print(\"Gradient boosting final report\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Gradient boosting final CM\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100) #default uses decision stump"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
